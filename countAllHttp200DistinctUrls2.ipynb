{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Installation\n",
    "// https://github.com/helgeho/ArchiveSpark/blob/master/notebooks/Selected_Title-and-Text.ipynb\n",
    "\n",
    "// install libraries\n",
    "\n",
    "import org.archive.archivespark._\n",
    "import org.archive.archivespark.functions._\n",
    "import org.archive.archivespark.specific.warc._\n",
    "\n",
    "\n",
    "// prepare session for creating data frames\n",
    "// https://sparkbyexamples.com/spark/different-ways-to-create-a-spark-dataframe/\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{Row, SparkSession}\n",
    "\n",
    "val session = spark.newSession\n",
    "\n",
    "val spark2 = spark\n",
    "val session2 = spark2.newSession\n",
    "\n",
    "import spark2.implicits._\n",
    "\n",
    "// data files - generic path from docker run -v\n",
    "val cdxPath = \"/data/arc_cdx/*.cdx\"\n",
    "val warcPath = \"/data/warc\"\n",
    "\n",
    "\n",
    "// collect all records\n",
    "\n",
    "val r = ArchiveSpark.load(WarcSpec.fromFiles(cdxPath, warcPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "// count all distinct urls with http 200\n",
    "\n",
    "val r1996 = r.filter(r => r.timestamp.startsWith(\"1996\") && r.status == 200)\n",
    "val r1997 = r.filter(r => r.timestamp.startsWith(\"1997\") && r.status == 200)\n",
    "val r1998 = r.filter(r => r.timestamp.startsWith(\"1998\") && r.status == 200)\n",
    "val r1999 = r.filter(r => r.timestamp.startsWith(\"1999\") && r.status == 200)\n",
    "val r2000 = r.filter(r => r.timestamp.startsWith(\"2000\") && r.status == 200)\n",
    "val r2001 = r.filter(r => r.timestamp.startsWith(\"2001\") && r.status == 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 1996\n",
    "val m1996 = r1996.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df1996 = session.createDataFrame(m1996).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "// 1997\n",
    "val m1997 = r1997.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df1997 = session.createDataFrame(m1997).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "// 1998\n",
    "val m1998 = r1998.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df1998 = session.createDataFrame(m1998).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "// 1999\n",
    "val m1999 = r1999.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df1999 = session.createDataFrame(m1999).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "// 2000\n",
    "val m2000 = r2000.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df2000 = session.createDataFrame(m2000).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()\n",
    "// 2001\n",
    "val m2001 = r2001.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df2001 = session.createDataFrame(m2001).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|count(DISTINCT originalUrl)|\n",
      "+---------------------------+\n",
      "|                      72166|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1996.agg(countDistinct(\"originalUrl\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+---------------------------+\n",
      "|count(DISTINCT originalUrl)|\n",
      "+---------------------------+\n",
      "|                    1087617|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1997.agg(countDistinct(\"originalUrl\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+---------------------------+\n",
      "|count(DISTINCT originalUrl)|\n",
      "+---------------------------+\n",
      "|                     859477|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1998.agg(countDistinct(\"originalUrl\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+---------------------------+\n",
      "|count(DISTINCT originalUrl)|\n",
      "+---------------------------+\n",
      "|                    1152859|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1999.agg(countDistinct(\"originalUrl\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+---------------------------+\n",
      "|count(DISTINCT originalUrl)|\n",
      "+---------------------------+\n",
      "|                    2951183|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2000.agg(countDistinct(\"originalUrl\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+---------------------------+\n",
      "|count(DISTINCT originalUrl)|\n",
      "+---------------------------+\n",
      "|                   12211565|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2001.agg(countDistinct(\"originalUrl\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// another method & data from countAllHttp200DistinctUrls | pls not run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val r1996d = r1996.distinctValue(_.originalUrl) {(r1, r2) => Seq(r1, r2).maxBy(_.timestamp)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"record\" : {\n",
       "        \"redirectUrl\" : \"-\",\n",
       "        \"timestamp\" : \"19961108220612\",\n",
       "        \"digest\" : \"4WH4EDQGSHBHW5KNBBUCVKNQHW27C36E\",\n",
       "        \"originalUrl\" : \"http://smok.krakus.ternet.pl:80/firmy/opi/badnauk.html\",\n",
       "        \"surtUrl\" : \"pl,ternet,krakus,smok)/firmy/opi/badnauk.html\",\n",
       "        \"mime\" : \"text/html\",\n",
       "        \"compressedSize\" : 1558,\n",
       "        \"meta\" : \"-\",\n",
       "        \"status\" : 200\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1996d.peekJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72166"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1996d.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087617"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val r1997d = r1997.distinctValue(_.originalUrl) {(r1, r2) => Seq(r1, r2).maxBy(_.timestamp)}\n",
    "r1997d.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "859477"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val r1998d = r1998.distinctValue(_.originalUrl) {(r1, r2) => Seq(r1, r2).maxBy(_.timestamp)}\n",
    "r1998d.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152859"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val r1999d = r1999.distinctValue(_.originalUrl) {(r1, r2) => Seq(r1, r2).maxBy(_.timestamp)}\n",
    "r1999d.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2951183"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val r2000d = r2000.distinctValue(_.originalUrl) {(r1, r2) => Seq(r1, r2).maxBy(_.timestamp)}\n",
    "r2000d.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12211565"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val r2001d = r2001.distinctValue(_.originalUrl) {(r1, r2) => Seq(r1, r2).maxBy(_.timestamp)}\n",
    "r2001d.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArchiveSpark",
   "language": "",
   "name": "archivespark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
