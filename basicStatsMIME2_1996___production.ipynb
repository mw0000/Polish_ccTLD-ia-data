{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 1. Installation\n",
    "\n",
    "//install libraries\n",
    "import org.archive.archivespark._\n",
    "import org.archive.archivespark.functions._\n",
    "import org.archive.archivespark.specific.warc._\n",
    "\n",
    "// data files - generic path from docker run -v\n",
    "val cdxPath = \"/data/arc_cdx/*.cdx\"\n",
    "val warcPath = \"/data/warc\"\n",
    "\n",
    "import org.apache.spark.sql.{Row, SparkSession}\n",
    "\n",
    "val session = spark.newSession\n",
    "\n",
    "// collect all records\n",
    "\n",
    "val r = ArchiveSpark.load(WarcSpec.fromFiles(cdxPath, warcPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val researchYear = \"1996\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 2. Count ALL objects from research Year\n",
    "// 2.1 get data for text/html & HTTP 200 for each Year\n",
    "val t1 = r.filter(r => r.timestamp.startsWith(researchYear))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 3. generate basic data frame\n",
    "\n",
    "val m = t1.map(f=> (f.originalUrl,f.digest,f.status,f.mime))\n",
    "val df = session.createDataFrame(m).toDF(\"originalUrl\",\"digest\",\"status\",\"mime\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.count\n",
    "import org.apache.spark.sql.functions._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|count(DISTINCT originalUrl)|\n",
      "+---------------------------+\n",
      "|                      38045|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df(\"mime\") === \"text/html\").select(countDistinct(\"originalUrl\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+---------------------------+\n",
      "|count(DISTINCT originalUrl)|\n",
      "+---------------------------+\n",
      "|                      72229|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct(\"originalUrl\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "+-------------------------+-----+\n",
      "|mime                     |URLs |\n",
      "+-------------------------+-----+\n",
      "|text/html                |38045|\n",
      "|image/gif                |21091|\n",
      "|text/plain               |7951 |\n",
      "|image/jpeg               |4105 |\n",
      "|application/postscript   |179  |\n",
      "|image/x-xbitmap          |145  |\n",
      "|unk                      |134  |\n",
      "|audio/x-wav              |113  |\n",
      "|application/zip          |85   |\n",
      "|application/octet-stream |75   |\n",
      "|application/pdf          |70   |\n",
      "|application/x-troff      |55   |\n",
      "|application/x-dvi        |44   |\n",
      "|application/x-tar        |21   |\n",
      "|application/x-tex        |20   |\n",
      "|application/x-msdownload |15   |\n",
      "|video/mpeg               |14   |\n",
      "|audio/x-pn-realaudio     |9    |\n",
      "|application/rtf          |8    |\n",
      "|application/x-excel      |8    |\n",
      "|image/tiff               |7    |\n",
      "|audio/basic              |4    |\n",
      "|application/mac-binhex40 |3    |\n",
      "|application/x-troff-man  |3    |\n",
      "|video/quicktime          |3    |\n",
      "|image/x-xpixmap          |2    |\n",
      "|application/x-sh         |2    |\n",
      "|multipart/x-zip          |2    |\n",
      "|unknown                  |2    |\n",
      "|application/msword       |2    |\n",
      "|text/x-server-parsed-html|1    |\n",
      "|gzip.zip                 |1    |\n",
      "|audio/x-aiff             |1    |\n",
      "|application/x-wais-source|1    |\n",
      "|multipart/x-tar          |1    |\n",
      "|audio/wav                |1    |\n",
      "|application/octet-string |1    |\n",
      "|x-world/x-vrml           |1    |\n",
      "|x-music/x-midi           |1    |\n",
      "|audio/x-midi             |1    |\n",
      "|audio/x-realaudio        |1    |\n",
      "|video/x-msvideo          |1    |\n",
      "+-------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"mime\").agg(countDistinct(\"originalUrl\") as \"URLs\").orderBy(desc(\"URLs\")).show(100,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(\"mime\").agg(countDistinct(\"originalUrl\") as \"URLs\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArchiveSpark",
   "language": "",
   "name": "archivespark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
